%\VignetteIndexEntry{practical2}
%\VignetteEngine{Sweave}

<<echo=FALSE>>=
results='hide';echo=FALSE
@
\documentclass[a4paper,justified,openany]{tufte-handout}
<<setup, echo=FALSE, cache=FALSE>>=
dir.create("graphics", showWarnings = FALSE)
library("knitr")
fname = ifelse(echo, "solutions2-", "practical2-")
opts_chunk$set(self.contained=FALSE, tidy = TRUE, 
              cache = TRUE, size = "small", message = FALSE,
              fig.path=paste0('knitr_figure/', fname), 
               cache.path=paste0('knitr_cache/',fname), 
               fig.align='center', 
               dev='pdf', fig.width=5, fig.height=5)

knit_hooks$set(par=function(before, options, envir){
    if (before && options$fig.show!='none') {
        par(mar=c(3,3,2,1),cex.lab=.95,cex.axis=.9,
            mgp=c(2,.7,0),tcl=-.01, las=1)
}}, crop=hook_pdfcrop)
opts_knit$set(out.format = "latex")
options(width=58)
@
\usepackage{amsmath}
\usepackage{graphicx}
\setkeys{Gin}{width=\linewidth,totalheight=\textheight,keepaspectratio}
\graphicspath{{graphics/}}
\title{Predictive Analytics: practical 2 \Sexpr{ifelse(echo, "solutions", "")}}
\date{} % if the \date{} command is left out, the current date will be used

\usepackage{booktabs}
\usepackage{units}
\usepackage{fancyvrb}
\fvset{fontsize=\normalsize}
\newcommand{\cc}{\texttt}
\graphicspath{{../graphics/}}
\setcounter{secnumdepth}{2}
\usepackage{microtype}

\begin{document}
\maketitle% this prints the handout title, author, and date

\section*{The \cc{OJ} data set}

The \cc{OJ} data set from the \cc{ISLR} package contains information on which of two brands of orange juice customers purchased\sidenote{The response variable is \cc{Purchase}.} and can be loaded using
<<>>=
data(OJ, package = "ISLR")
@

\noindent After loading the \cc{caret} and \cc{nclRpredictive} package 
<<message = FALSE>>=
library("caret")
library("nclRpredictive")
@

\noindent make an initial examination of the relationships between each of the predictors and the response\sidenote{Use the \cc{plot} function with a model formula or the \cc{pairs} function.}
<<eval = echo, fig.keep="none">>=
par(mfrow = c(4, 5), mar= c(4, .5, .5, .5))
plot(Purchase ~ ., data = OJ)
@ 

\section*{Initial model building}

\begin{itemize}
\item To begin, create a logistic regression model that takes into consideration the prices of the two brands of orange juice, \cc{PriceCH} and \cc{PriceMM}.\sidenote{Hint: Use the \cc{train} function, with \cc{method = 'glm'}.  Look at the help page for the data set to understand what these
variables represent.}
<<echo=echo, cache=TRUE>>=
m1 = train(Purchase ~ PriceCH + PriceMM,
    data = OJ, method = "glm")
@
  \item What proportion of purchases does this model get right?
<<echo=echo, results=results>>=
mean(predict(m1) != OJ$Purchase)
@   
  \item How does this compare to if we used no model?
<<echo=echo, cache=TRUE, results=results>>=
# with no model we essentially predict according to 
# proportion of observations in data
probs = table(OJ$Purchase)/nrow(OJ)
preds = sample(levels(OJ$Purchase), prob = probs)
mean(preds != OJ$Purchase)
@ 
\end{itemize}

\section*{Visualising the boundary}

The \cc{nclRpredictive} package contains following code produces a plot of the decision boundary as seen in figure~\ref{fig:purchaseboundary}.
<<figure1,fig.keep="none", echo=2>>=
setnicepar()
boundary_plot(m1,OJ$PriceCH, OJ$PriceMM, OJ$Purchase,
              xlab="Price CH", ylab="Price MM")
@
\noindent Run the boundary code above, and make sure you get a similar plot.

\begin{marginfigure}
<<figure1,echo=FALSE>>=
@
  \caption{Examining the decision boundary for orange juice brand purchases by price.}
  \label{fig:purchaseboundary}
\end{marginfigure}

\begin{itemize}
  \item What happens if we add an interaction term? How does the boundary change?
<<echo=echo, tidy=TRUE>>=
# We now have a curved decision boundary. 
# There are two regions of where we would predict MM, bottom left, and a tiny one up in the top right.
@
\item Try adding polynomial terms.
\end{itemize}

\section*{Using all of the predictors}

\begin{itemize}
  \item Fit a logistic regression model using all of the predictors.
<<echo=echo, warning=FALSE>>=
mLM = train(Purchase ~ ., data = OJ, method = "glm")
@ 
  \item Is there a problem?
<<echo=echo>>=
## YES!
@

\noindent We can view the most recent warning messages by using the \cc{warnings} function
<<eval=FALSE>>=
warnings()
@

<<warning = FALSE, echo = FALSE, cache=TRUE>>=
m_log = train(Purchase ~ ., data = OJ, method = "glm")
@

\noindent This suggests some rank--deficient fit problems,

\item Look at the final model, you should notice that a number of parameters have not been estimated
<<echo=echo, results=results>>=
m_log$finalModel
@

\noindent The help page
<<eval = FALSE>>=
?ISLR::OJ
@
\noindent gives further insight: the \cc{PriceDiff} variable is a linear combination of \cc{SalePriceMM} and \cc{SalePriceCH} so we should remove this. In addition the \cc{StoreID} and \cc{STORE} variable are different encodings of the same information so we should remove one of these too. We also have \cc{DiscCH} and \cc{DiscMM} which are the differences between \cc{PriceCH} and \cc{SalePriceCH} and \cc{PriceMM} and \cc{SalePriceMM} respectively and \cc{ListPriceDiff} is a linear combination of these prices. Removing all of these variables allows the model to be fit and all parameters to be estimated.\sidenote{This is to highlight that we need to understand what we have in our data.}
<<cache=TRUE>>=
OJsub = OJ[,!(colnames(OJ) %in% c("STORE", "SalePriceCH",
           "SalePriceMM","PriceDiff", "ListPriceDiff"))]
OJsub$Store7 = as.numeric(OJsub$Store7) - 1
m_log = train(Purchase ~ ., data = OJsub, method = "glm")
@

\noindent The problem of linear combinations of predictors can be shown with this simple theoretical example. Suppose we have a response $y$ and three predictors $x_1$, $x_2$ and the linear combination $x_3 = (x_1 + x_2)$. On fitting a linear model we try to find estimates of the parameters in the equation
\[
y = \beta_0 + \beta_1 x_1 + \beta_2 x_2 + \beta_3 (x_1 + x_2).
\]
\noindent However we could just as easily rewrite this as
\begin{align*}
y &= \beta_0 + \beta_1 x_1 + \beta_2 x_2 + \beta_3 (x_1 + x_2) \\
&= \beta_0 + (\beta_1 + \beta_3) x_1 + (\beta_2 + \beta_3) x_2 \\
&= \beta_0 + \beta_1^{\ast} x_1 + \beta_2^{\ast} x_2.
\end{align*}
This leads to a rank--deficient model matrix, essentially we can never find the value of the $\beta_3$ due to the fact we have the linear combination of predictors.

We could achieve the same using the \cc{caret} package function \cc{findLinearCombos}. The function takes a model matrix as an argument. We can create such a matrix using the 
\cc{model.matrix} function with our formula object
<<cache=TRUE>>=
remove = findLinearCombos(
               model.matrix(Purchase ~ ., data = OJ))
@
\noindent The output list has a component called \cc{remove} suggesting which variables should be removed to get rid of linear combinations
<<cache=TRUE, tidy=TRUE>>=
(badvar = colnames(OJ)[remove$remove])
OJsub = OJ[, -remove$remove]
@
  \item How accurate is this new model using more predictors?]
<<echo=echo, cache=TRUE, results=results>>=
# the corrected model
remove = findLinearCombos(model.matrix(Purchase~., data = OJ))
(badvar = colnames(OJ)[remove$remove])
OJsub = OJ[,-(remove$remove)]
mLM = train(Purchase~., data = OJsub, method = "glm")
mean(predict(mLM,OJsub) == OJsub$Purchase)
@ 
  \item What are the values of sensitivity and specificity?
<<echo=echo, results=results>>=
## could use confusionMatrix
(cmLM = confusionMatrix(predict(mLM,OJsub),OJsub$Purchase))

# or 
sensitivity(predict(mLM,OJsub),OJsub$Purchase)
specificity(predict(mLM,OJsub),OJsub$Purchase)
@ 
  \item What does this mean?
<<echo=echo, tidy=TRUE>>=
#The model is fairly good at picking up both positive events, person buys CH, and negative events, MM.
@

\end{itemize}

\section*{ROC curves}

\begin{marginfigure}
<<figure2, eval=TRUE,echo=FALSE, message=FALSE, results="hide">>=
library("pROC")
setnicepar()
curve = roc(response = OJsub$Purchase, 
  predictor = predict(m_log, type = "prob")[,"CH"])
## this makes CH the event of interest
plot(curve, legacy.axes = TRUE)
auc(curve)
@
  \caption{An example of a ROC curve for the logistic regression classifier. We can overlay ROC curves by adding the \cc{add = TRUE} argument.}
  \label{fig:roc}
\end{marginfigure}

If we were interested in the area under the ROC curve, we could retrain the model using the \cc{twoClassSummary} function as an argument to a train control object. Alternatively we can
use the \cc{pROC} package

<<message=FALSE>>=
library("pROC")
@

\noindent This also allows us to view the ROC curve, via

<<figure2, echo=3:7, eval=FALSE, message=FALSE>>=
@


\section*{Other classification models}

\begin{itemize}
  \item Try fitting models using the other classification algorithms we have seen so far. To begin with, just have two covariates and use the \cc{boundary\_plot} function to visualise
  the results\marginnote{We have seen LDA, QDA, KNN and logistic regression.}
<<echo=echo, cache=TRUE, results=results, message=FALSE>>=
mKNN = train(Purchase~., data = OJsub, method = "knn")
mLDA = train(Purchase~., data = OJsub, method = "lda")
mQDA = train(Purchase~., data = OJsub, method = "qda")
cmKNN = confusionMatrix(predict(mKNN,OJsub),OJsub$Purchase)
cmLDA = confusionMatrix(predict(mLDA,OJsub),OJsub$Purchase)
cmQDA = confusionMatrix(predict(mQDA,OJsub),OJsub$Purchase)
(info = data.frame(Model = c("logistic","knn","lda","qda"),
           Accuracy = c(cmLM$overall["Accuracy"],
               cmKNN$overall["Accuracy"],
               cmLDA$overall["Accuracy"],
               cmQDA$overall["Accuracy"]),
           Sensitivity = c(cmLM$byClass["Sensitivity"],
               cmKNN$byClass["Sensitivity"],
               cmLDA$byClass["Sensitivity"],
               cmQDA$byClass["Sensitivity"]),
           Specificity = c(cmLM$byClass["Specificity"],
               cmKNN$byClass["Specificity"],
               cmLDA$byClass["Specificity"],
               cmQDA$byClass["Specificity"])))
@   
  \item How do they compare?
<<echo=echo, tidy=FALSE>>=
#Logistic regression and LDA have highest accuracy, QDA is poorest at classifying events, KNN gives most false positives
@

  \item How does varying the number of nearest neighbours in a KNN affect the model fit?
<<echo=echo, tidy=TRUE, cache=TRUE, results=results>>=
#Accuracy increases at first with knn before then getting worse after a peak value of 9.
(mKNN2 = train(Purchase~., data = OJsub, method = "knn",
    tuneGrid = data.frame(k = 1:30)))
@
\end{itemize}

\noindent The KNN algorithm described in the notes can also be used for regression problems. In this case the predicted response is the mean of the $k$ nearest neighbours.
\begin{itemize}
  \item Try fitting the KNN model for the regression problem in practical 1. 
<<warning =FALSE, fig.keep="none", echo=echo, cache=TRUE, results=results, message=FALSE>>=
library("nclRpredictive")
data(FuelEconomy, package = "AppliedPredictiveModeling")
regKNN = train(FE~., data = cars2010, method = "knn")
regLM = train(FE~., data = cars2010, method = "lm")
regKNN= validate(regKNN)
regLM = validate(regLM)
mark(regKNN)
mark(regLM)
@ 

  \item How does this compare to the linear regression models?

<<echo=echo, tidy=TRUE>>=
#The KNN regression model is not as good as the linear model at predicting the test set. It overestimates more at the lower end.
@

\end{itemize}

\section*{An example with more than two classes}

The \cc{Glass} data set in the \cc{mlbench} package is a data frame containing examples of the chemical analysis of $7$ different types of glass. The goal is to be able to predict which category glass falls into based on the values of the $9$ predictors.
<<>>=
data(Glass, package = "mlbench")
@

\noindent A logistic regression model is typically not suitable for more than $2$ classes, so try fitting the other models using a training set that consists of 90\% of the available data.\marginnote{The function \cc{createDataPartition} can be used here, see notes for a reminder.}

\end{document}
